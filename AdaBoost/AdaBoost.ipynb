{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdaBoost",
      "provenance": [],
      "authorship_tag": "ABX9TyPRkwpq3E0W3Q6Gz1onBBF3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunbommagunta/TreeModels/blob/main/AdaBoost/AdaBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CJjqRjyAOHx"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyUQpXz5AsTz"
      },
      "source": [
        "breast_cancer = load_breast_cancer()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujvHhqgNA8vG",
        "outputId": "c628dad1-a8cb-46c7-d6be-15e47ac02b61"
      },
      "source": [
        "dir(breast_cancer)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DESCR', 'data', 'feature_names', 'filename', 'target', 'target_names']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCDuHuhwBIlL"
      },
      "source": [
        "X = pd.DataFrame(breast_cancer.data,columns = breast_cancer.feature_names)\n",
        "y = breast_cancer.target"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "sMkp9gQwBheO",
        "outputId": "e4fee67e-05d5-4792-91ef-0338dd79c969"
      },
      "source": [
        "X"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0          17.99         10.38  ...          0.4601                  0.11890\n",
              "1          20.57         17.77  ...          0.2750                  0.08902\n",
              "2          19.69         21.25  ...          0.3613                  0.08758\n",
              "3          11.42         20.38  ...          0.6638                  0.17300\n",
              "4          20.29         14.34  ...          0.2364                  0.07678\n",
              "..           ...           ...  ...             ...                      ...\n",
              "564        21.56         22.39  ...          0.2060                  0.07115\n",
              "565        20.13         28.25  ...          0.2572                  0.06637\n",
              "566        16.60         28.08  ...          0.2218                  0.07820\n",
              "567        20.60         29.33  ...          0.4087                  0.12400\n",
              "568         7.76         24.54  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3W5KfnkBiKa"
      },
      "source": [
        "y = np.expand_dims(y,axis = 1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YUqQAFmBx3Y",
        "outputId": "1625dbc3-da8e-4040-ffd5-be01737fc723"
      },
      "source": [
        "y[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpyL7g8VCJe8"
      },
      "source": [
        "clf = AdaBoostClassifier(\n",
        "    DecisionTreeClassifier(),\n",
        "    n_estimators = 200\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLnpBFZsCdX6"
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P71uqPVeDto8",
        "outputId": "f9ed5f80-3c12-4ba8-c936-3c867d8cf026"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(455, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTghUDU4DtgH",
        "outputId": "e0f705aa-2acd-47d2-df2c-d7f860a8e846"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(455, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38jFhG-OCmZK",
        "outputId": "1d6c943d-c6cb-4c44-9573-1d98c8f94a13"
      },
      "source": [
        "clf.fit(X_train,y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
              "                                                         class_weight=None,\n",
              "                                                         criterion='gini',\n",
              "                                                         max_depth=None,\n",
              "                                                         max_features=None,\n",
              "                                                         max_leaf_nodes=None,\n",
              "                                                         min_impurity_decrease=0.0,\n",
              "                                                         min_impurity_split=None,\n",
              "                                                         min_samples_leaf=1,\n",
              "                                                         min_samples_split=2,\n",
              "                                                         min_weight_fraction_leaf=0.0,\n",
              "                                                         presort='deprecated',\n",
              "                                                         random_state=None,\n",
              "                                                         splitter='best'),\n",
              "                   learning_rate=1.0, n_estimators=200, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P1IF-hHCpNP"
      },
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJEdnsRPCuKJ"
      },
      "source": [
        "cm = confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "jZAMnt2GFhsC",
        "outputId": "845ed683-ae31-4303-ebfe-bb494f9d8f60"
      },
      "source": [
        "con_mat = sns.heatmap(cm,annot = True)\n",
        "con_mat.set(xlabel=\"Predicted\", ylabel = \"Actual\");"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEGCAYAAABIGw//AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVuElEQVR4nO3de7hdZX3g8e/vhIQgQW6BGAIWOiCWoRX6AKIoRqIBxBZtffDS8cloxoOMoIIzBhxai5cWlaIodOSUIKkKhWIZEFsujTDAoJCg4ZYIxACSG5FKhFAKOef85o+9Asdczt4n2Xuv9xy/nzzvs/daa+93/ZKc55c3v/W+a0VmIkkqT0/dAUiSNs8ELUmFMkFLUqFM0JJUKBO0JBVqu7oD2JKnjn+L00u0iYN/tKbuEFSg1WuXxLb2sf6pZS3nnPGTf3ebz9cKR9CSVKhiR9CS1FWDA3VHsAkTtCQBDPTXHcEmTNCSBGQO1h3CJkzQkgQwaIKWpDI5gpakQnmRUJIK5QhaksqUzuKQpEJ5kVCSCmWJQ5IK5UVCSSqUI2hJKpQXCSWpUF4klKQyZVqDlqQyWYOWpEJZ4pCkQjmClqRCDayvO4JNmKAlCSxxSFKxCixx+FRvSYLGCLrV1kRE7BIRV0fEzyJiSUS8ISJ2i4ibI+KR6nXXZv2YoCUJ2pqggQuAGzLztcDrgCXAmcD8zDwAmF9tD8sShyQB2aaLhBGxM3A08F8BMvNF4MWIOBGYXn1sHnArMGe4vhxBSxI0atAttojojYiFQ1rvkJ72A34JfCsifhoRl0TEjsCUzFxVfWY1MKVZSI6gJQlGNIsjM/uAvi0c3g74Q+C0zLwrIi5go3JGZmZEZLPzOIKWJBjRCLqJ5cDyzLyr2r6aRsJ+MiKmAlSva5p1ZIKWJGjbRcLMXA08EREHVrtmAIuB64BZ1b5ZwLXNQrLEIUnQ7nnQpwHfjYgJwDLgQzQGxFdFxGzgceCkZp2YoCUJoL99N+zPzEXAYZs5NGMk/ZigJQmKXElogpYk8F4cklQsR9CSVChH0JJUKEfQklSoNs7iaBcTtCQBZNOV111ngpYksAYtScUyQUtSobxIKEmFGhioO4JNmKAlCSxxSFKxTNCSVChr0JJUphx0HrQklckShyQVylkcklQoR9CSVCgTtFrS08MuX+9j8Klf8sxfnsWkT5/NdgccCP399D/8M9Z9/bwi/zum7unp6eHGW/+R1SvX8MH3nVJ3OGNDgTdL6qk7AG1q4onvof8Xj7+0/cItN7P2Ix9k7SkfIiZsz8Tj3lljdCrBR075II88tKzuMMaWwcHWW5d0LEFHxGsjYk5EfL1qcyLi9zp1vrGiZ/IeTDjiSF648fqX9q1fcNfL7x9aQs/kPeoITYWYutcU3jbzLXz321fXHcrYMpitty7pSIKOiDnAPwAB3F21AK6IiDM7cc6xYseTT+W5ud/c/A/BuHFMnDGTFxfe3f3AVIzP//VZfP4vziMLrJmOagMDrbcu6dQIejZweGaem5nfqdq5wBHVsc2KiN6IWBgRC//+iVUdCq1c4494A4Nr1zKw9OHNHp/0sTNY/8C99D94X5cjUynefux0nvrlr7jv3sV1hzLm5OBgy62ZiHgsIu6PiEURsbDat1tE3BwRj1Svuzbrp1MXCQeBvYDHN9o/tTq2WZnZB/QBPHX8W8qr2HfY+IMOZsKRb2TC4a8nxk8gXrEjk/7n/2LdV77IDh+YRey8M+u+cF7dYapGh7/+UGYe/1ZmzDya7befwKSdJnHhxV/i1JPn1B3a6Nf+0sVbM/OpIdtnAvMz89yqknAmMOxfXGQHrlxGxHHAhcAjwBPV7lcD+wOnZuYNzfr4bUzQQ43//UPY4U/fyzN/eRbbH3sCE2e+g1+fdTq8+GLdodXq4B+tqTuEYrzxTYdzyqkfdhYHsHrtktjWPp77wn9pOefsePZ3hj1fRDwGHDY0QUfEQ8D0zFwVEVOBWzPzwOH66cgIOjNviIjX0ChpTKt2rwAWZKbzw0Zo0mlnMLjmSXY5/28BeOHO23n+8nk1RyWNMSMYQUdEL9A7ZFdfVQHYIIGbIiKBi6tjUzJzQ+12NTCl2Xk6Ng86MweBH3eq/7Fu/f2LWH//IgD+7Z0zao5GJbrzjgXceceCusMYO/pbHzsOLcduwZsyc0VE7AncHBE/2+j7WSXvYTkPWpKgcbvRVluzrjJXVK9rgGtoVBOerEobVK9N63UmaEmCts2DjogdI2KnDe+BmcADwHXArOpjs4Brm4XkUm9JgnbOK58CXBMR0Mixl1fX5RYAV0XEbBoz3E5q1pEJWpKgbdPsMnMZ8LrN7P83YEQXlEzQkgRdXcLdKhO0JEGRd4g0QUsSPpNQksplgpakQhV4d0ATtCSBI2hJKpYJWpLKlAOWOCSpTI6gJalMTrOTpFKZoCWpUOWVoE3QkgSQ/eVlaBO0JIEjaEkqlRcJJalUjqAlqUyOoCWpVI6gJalM2V93BJsyQUsSkI6gJalQJmhJKpMjaEkqVIkJuqfuACSpBDkQLbdWRMS4iPhpRFxfbe8XEXdFxNKIuDIiJjTrwwQtSTRG0K22Fn0CWDJk+0vAVzNzf+BpYHazDkzQkgTkYLTcmomIvYETgEuq7QCOAa6uPjIPeFezfkzQksTIRtAR0RsRC4e03o26+xrwaV6eG7I7sDbzpdnWy4FpzWLyIqEkAZmt1ZYbn80+oG9zxyLincCazLwnIqZvS0wmaEmirbM4jgL+OCLeAUwEXglcAOwSEdtVo+i9gRXNOrLEIUnA4EC03IaTmWdl5t6ZuS/wPuCHmflnwC3Ae6qPzQKubRaTCVqSaO9Fwi2YA5wREUtp1KTnNvuCJQ5Jgm1JvFvuM/NW4Nbq/TLgiJF83wQtSUCWdzvoLSfoiPgGsMWQM/PjHYlIkmrQiRH0thpuBL2wa1FIUs1GMs2uW7aYoDNzXjcDkaQ6DbR4j41ualqDjog9aFx9PIjGnD4AMvOYDsYlSV1V4gi6lWl236Vxw4/9gHOAx4AFHYxJkrquC9PsRqyVBL17Zs4F1mfm/83MD9O46YckjRmZrbduaWWa3frqdVVEnACsBHbrXEiS1H2jbRbHBl+IiJ2BTwHfoLGu/PSORiVJXTYwWN7C6qYJOjOvr97+GnhrZ8ORpHqMqoUqG0TEt9jMgpWqFi1JY8JggbM4WilxXD/k/UTg3TTq0JI0ZpQ4za6VEsf3hm5HxBXAHR2LSJJqMCpLHJtxALBnuwPZ2KvmL+30KTQKPb/y9rpD0Bg1KkscEfEsv1mDXk1jZaEkjRmjdRbHTt0IRJLqVGCFo/lKwoiY38o+SRrNBjNabt0y3P2gJwKvACZHxK7AhqheSQuPC5ek0WS0zeI4GfgksBdwDy8n6GeACzsclyR1Vfse6t0+w90P+gLggog4LTO/0cWYJKnrkvJG0K1cthyMiF02bETErhHx3zsYkyR1XX9Gy61bWknQH8nMtRs2MvNp4COdC0mSui+Jllu3tLJQZVxERGZjnU1EjAMmdDYsSequEmvQrYygbwCujIgZETEDuAL4l86GJUnd1a4RdERMjIi7I+LeiHgwIs6p9u8XEXdFxNKIuDIimg50W0nQc4AfAh+t2v3ADi18T5JGjcERtCZeAI7JzNcBhwDHRcSRwJeAr2bm/sDTwOxmHTVN0Jk5CNxF41mER9B43NWS5jFK0ugxQLTchpMN66rN8VVLGrnz6mr/POBdzWIabqHKa4D3V+0p4Mrq5N60X9KYM5InXkVEL9A7ZFdfZvYNOT6OxvqR/YGLgJ8DazOzv/rIclpY8DfcRcKfAbcD78zMpdVJfdSVpDFpcASzM6pk3DfM8QHgkGqK8jXAa7cmpuFKHH8CrAJuiYi/qy4QljeTW5LaIEfQWu6zMUX5FuANwC4RsWFQvDewotn3t5igM/P/ZOb7aGT+W2gs+94zIv53RMwcQYySVLx2XSSMiD02LO6LiB2At9O4bncL8J7qY7OAa5vF1MpFwucy8/LM/CMaWf+neD9oSWPMYETLrYmpNCoP9wELgJurh2/PAc6IiKXA7sDcZh2N6Ikq1SrCYWsvkjQaDbSpn8y8Dzh0M/uX0ZgJ17KteeSVJI05I5nF0S0maEliZLM4usUELUmU+cgrE7QkYYlDkopV4t3sTNCSBAw4gpakMjmClqRCmaAlqVBdfNRgy0zQkoQjaEkqVruWereTCVqScB60JBXLEockFcoELUmF8l4cklQoa9CSVChncUhSoQYLLHKYoCUJLxJKUrHKGz+boCUJcAQtScXqj/LG0CZoSaLMEkdP3QFIUgkGR9CGExH7RMQtEbE4Ih6MiE9U+3eLiJsj4pHqdddmMZmgJYnGNLtWWxP9wKcy8yDgSOBjEXEQcCYwPzMPAOZX28MyQUsSjRJHq23YfjJXZeZPqvfPAkuAacCJwLzqY/OAdzWLyQQtSYysxBERvRGxcEjr3VyfEbEvcChwFzAlM1dVh1YDU5rF5EVCSQIGRnCZMDP7gL7hPhMRk4DvAZ/MzGciXr7ZR2ZmRPNpI46gJYn2XSQEiIjxNJLzdzPzn6rdT0bE1Or4VGBNs35M0JIE5Ah+DScaQ+W5wJLMPH/IoeuAWdX7WcC1zWKyxCFJtHUl4VHAB4H7I2JRte8zwLnAVRExG3gcOKlZRybowh07czrnn/85xvX0cOm3ruDLX7mo7pBUk2eeXcdnz/0aS5c9DhF8/jOnM3HCBD73lW/wwovrGTduHH/+Pz7G7x90YN2hjkrtuptdZt4BbOnu0jNG0pcJumA9PT18/YIvctw73s/y5av48Y/+me9ffxNLljxSd2iqwblf+yZHvf4wvvrFs1m/fj3P/8cLfOrP/4pTPvxnvPkNh3PbnXfzN387l8su/HLdoY5KriTUiBxx+KH8/OeP8eijv2D9+vVcddW1/PEfHVt3WKrBs+ue4557H+BPq7//8ePH88qdJhERrHvu3wFY99y/s+fk3esMc1TrJ1tu3eIIumB7TXsVTyxf+dL28hWrOOLwQ2uMSHVZsXI1u+6yM2d/8XweWrqMgw48gDM/+VHmfOJkTj7jbM676BJyMPnOxX9Td6ijVrOLf3Xo+gg6Ij40zLGXJn8PDj7XzbCkovUPDLDk4aW8990ncPVlF7HDDhOZ++2ruPKaHzDntF7mX/NtPv3xXv7ir79Wd6ijVjun2bVLHSWOc7Z0IDP7MvOwzDysp2fHbsZUpJUrVrPP3nu9tL33tKmsXLm6xohUl1ftOZkpe0zmD/7zawGYOf1NLH54Kdf9y7/ytulHAXDsMW/m/sUP1RnmqNauaXbt1JEEHRH3baHdTwvLG9WwYOEi9t9/P/bddx/Gjx/PSSedyPevv6nusFSDybvvxqv23INHH18OwI/vWcR/2vfV7DF5dxb89H4A7rpnEb+zz7Q6wxzVShxBd6oGPQU4Fnh6o/0B3Nmhc445AwMDfOKTZ/PPP7iccT09XDbvShYvfrjusFSTz5x+CnPO+TLr+9ezz15T+fxnTueYNx/JuRdcTP/AANtPmMBnP/3xusMctQayvBp0ZAeCioi5wLeq+YAbH7s8Mz/QrI/tJkwr709LtXt+5e11h6ACjZ/8u1uad9yyD/zOu1vOOZc/fs02n68VHRlBZ+bsYY41Tc6S1G0lzuJwmp0k4UNjJalY7Vrq3U4maEnCEockFavEWRwmaEnCEockFcuLhJJUKGvQklQoSxySVKhOrKreViZoSQIGHEFLUpkscUhSoSxxSFKhHEFLUqFKnGbnU70licZS71ZbMxFxaUSsiYgHhuzbLSJujohHqtddm/VjgpYkGiWOVlsLLgOO22jfmcD8zDwAmF9tD8sELUm0N0Fn5m3ArzbafSIwr3o/D3hXs35M0JJEYxZHqy0ieiNi4ZDW28IppmTmqur9alp4gLYXCSWJkc3iyMw+oG9rz5WZGRFNT+gIWpJozOJo9ddWejIipgJUr2uafcEELUnAQA623LbSdcCs6v0s4NpmX7DEIUm0dyVhRFwBTAcmR8Ry4LPAucBVETEbeBw4qVk/JmhJor0rCTPz/Vs4NGMk/ZigJYkyVxKaoCUJGPRmSZJUJkfQklSobZid0TEmaEnCEockFcsShyQVyhG0JBXKEbQkFWogB+oOYRMmaEnCh8ZKUrF8aKwkFcoRtCQVylkcklQoZ3FIUqFc6i1JhbIGLUmFsgYtSYVyBC1JhXIetCQVyhG0JBXKWRySVCgvEkpSoUoscfTUHYAklSBH8KuZiDguIh6KiKURcebWxuQIWpJo3wg6IsYBFwFvB5YDCyLiusxcPNK+TNCSRFtr0EcASzNzGUBE/ANwIjB2EnT/iyui7hhKERG9mdlXdxwqiz8X7TWSnBMRvUDvkF19Q/4upgFPDDm2HHj91sRkDXp06G3+Ef0W8ueiJpnZl5mHDWkd+YfSBC1J7bUC2GfI9t7VvhEzQUtSey0ADoiI/SJiAvA+4Lqt6ajYGrR+g3VGbY4/FwXKzP6IOBW4ERgHXJqZD25NX1Hi5GxJkiUOSSqWCVqSCmWCLly7loxq7IiISyNiTUQ8UHcs6iwTdMGGLBk9HjgIeH9EHFRvVCrAZcBxdQehzjNBl+2lJaOZ+SKwYcmofotl5m3Ar+qOQ51ngi7b5paMTqspFkldZoKWpEKZoMvWtiWjkkYfE3TZ2rZkVNLoY4IuWGb2AxuWjC4BrtraJaMaOyLiCuBHwIERsTwiZtcdkzrDpd6SVChH0JJUKBO0JBXKBC1JhTJBS1KhTNCSVCgTtDoiIgYiYlFEPBAR/xgRr9iGvi6LiPdU7y8Z7oZRETE9It64Fed4LCImb22MUieYoNUpz2fmIZl5MPAi8NGhByNiqx63lpn/LTMXD/OR6cCIE7RUIhO0uuF2YP9qdHt7RFwHLI6IcRHxlYhYEBH3RcTJANFwYXUf7H8F9tzQUUTcGhGHVe+Pi4ifRMS9ETE/Ival8Q/B6dXo/c0RsUdEfK86x4KIOKr67u4RcVNEPBgRlwDR3T8SqTkfGquOqkbKxwM3VLv+EDg4Mx+NiF7g15l5eERsD/y/iLgJOBQ4kMY9sKcAi4FLN+p3D+DvgKOrvnbLzF9FxDeBdZl5XvW5y4GvZuYdEfFqGqsyfw/4LHBHZn4uIk4AXI2n4pig1Sk7RMSi6v3twFwapYe7M/PRav9M4A821JeBnYEDgKOBKzJzAFgZET/cTP9HArdt6Cszt3R/5LcBB0W8NEB+ZURMqs7xJ9V3fxART2/l71PqGBO0OuX5zDxk6I4qST43dBdwWmbeuNHn3tHGOHqAIzPzPzYTi1Q0a9Cq043AKRExHiAiXhMROwK3Ae+tatRTgbdu5rs/Bo6OiP2q7+5W7X8W2GnI524CTtuwEREb/tG4DfhAte94YNe2/a6kNjFBq06X0Kgv/6R6AOrFNP5Xdw3wSHXs72ncue03ZOYvgV7gnyLiXuDK6tD3gXdvuEgIfBw4rLoIuZiXZ5OcQyPBP0ij1PGLDv0epa3m3ewkqVCOoCWpUCZoSSqUCVqSCmWClqRCmaAlqVAmaEkqlAlakgr1/wHWSNfkAPO/0QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "XfglcLdgFhiS",
        "outputId": "3f601629-7941-4301-cbd0-070f432e2135"
      },
      "source": [
        "'''\n",
        "Here we can observe that\n",
        "->42 times the true label is 0 and predicted is 0 (True Positives)\n",
        "->68 times the true label is 1 and predicted is 1 (True Negatives)\n",
        "->4 times the true label is 0 and predicted label is 1 (False Positive)\n",
        "->0 times the true label is 5 and predicted label is 0 (False Negative)\n",
        "'''"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nHere we can observe that\\n->32 times the true label is 0 and predicted is 0 (True Positives)\\n->76 times the true label is 1 and predicted is 1 (True Negatives)\\n->1 time the true label is 0 and predicted label is 1 (False Positive)\\n-> 5 times the true label is 5 and predicted label is 0 (False Negative)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OMeuKqxHsb2"
      },
      "source": [
        "matrix = classification_report(y_test,y_pred)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8MAOut3Hsj6",
        "outputId": "67459789-52d3-45c2-93c6-8327d36c9e21"
      },
      "source": [
        "print(matrix)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95        46\n",
            "           1       0.94      1.00      0.97        68\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N4V52vACx3B"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16EU1drDC2Z4",
        "outputId": "7249861e-a5b7-4525-8d19-453eebd39a8a"
      },
      "source": [
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9649122807017544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}